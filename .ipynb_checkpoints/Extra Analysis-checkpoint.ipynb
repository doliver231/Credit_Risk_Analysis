{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4903ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74eb6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a9c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a804c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"loan_amnt\", \"int_rate\", \"installment\", \"home_ownership\",\n",
    "    \"annual_inc\", \"verification_status\", \"issue_d\", \"loan_status\",\n",
    "    \"pymnt_plan\", \"dti\", \"delinq_2yrs\", \"inq_last_6mths\",\n",
    "    \"open_acc\", \"pub_rec\", \"revol_bal\", \"total_acc\",\n",
    "    \"initial_list_status\", \"out_prncp\", \"out_prncp_inv\", \"total_pymnt\",\n",
    "    \"total_pymnt_inv\", \"total_rec_prncp\", \"total_rec_int\", \"total_rec_late_fee\",\n",
    "    \"recoveries\", \"collection_recovery_fee\", \"last_pymnt_amnt\", \"next_pymnt_d\",\n",
    "    \"collections_12_mths_ex_med\", \"policy_code\", \"application_type\", \"acc_now_delinq\",\n",
    "    \"tot_coll_amt\", \"tot_cur_bal\", \"open_acc_6m\", \"open_act_il\",\n",
    "    \"open_il_12m\", \"open_il_24m\", \"mths_since_rcnt_il\", \"total_bal_il\",\n",
    "    \"il_util\", \"open_rv_12m\", \"open_rv_24m\", \"max_bal_bc\",\n",
    "    \"all_util\", \"total_rev_hi_lim\", \"inq_fi\", \"total_cu_tl\",\n",
    "    \"inq_last_12m\", \"acc_open_past_24mths\", \"avg_cur_bal\", \"bc_open_to_buy\",\n",
    "    \"bc_util\", \"chargeoff_within_12_mths\", \"delinq_amnt\", \"mo_sin_old_il_acct\",\n",
    "    \"mo_sin_old_rev_tl_op\", \"mo_sin_rcnt_rev_tl_op\", \"mo_sin_rcnt_tl\", \"mort_acc\",\n",
    "    \"mths_since_recent_bc\", \"mths_since_recent_inq\", \"num_accts_ever_120_pd\", \"num_actv_bc_tl\",\n",
    "    \"num_actv_rev_tl\", \"num_bc_sats\", \"num_bc_tl\", \"num_il_tl\",\n",
    "    \"num_op_rev_tl\", \"num_rev_accts\", \"num_rev_tl_bal_gt_0\",\n",
    "    \"num_sats\", \"num_tl_120dpd_2m\", \"num_tl_30dpd\", \"num_tl_90g_dpd_24m\",\n",
    "    \"num_tl_op_past_12m\", \"pct_tl_nvr_dlq\", \"percent_bc_gt_75\", \"pub_rec_bankruptcies\",\n",
    "    \"tax_liens\", \"tot_hi_cred_lim\", \"total_bal_ex_mort\", \"total_bc_limit\",\n",
    "    \"total_il_high_credit_limit\", \"hardship_flag\", \"debt_settlement_flag\"\n",
    "]\n",
    "\n",
    "target = [\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc020be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = Path('LoanStats_2019Q1.csv')\n",
    "df = pd.read_csv(file_path, skiprows=1)[:-2]\n",
    "df = df.loc[:, columns].copy()\n",
    "\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove the `Issued` loan status\n",
    "issued_mask = df['loan_status'] != 'Issued'\n",
    "df = df.loc[issued_mask]\n",
    "\n",
    "# convert interest rate to numerical\n",
    "df['int_rate'] = df['int_rate'].str.replace('%', '')\n",
    "df['int_rate'] = df['int_rate'].astype('float') / 100\n",
    "\n",
    "\n",
    "# Convert the target column values to low_risk and high_risk based on their values\n",
    "x = {'Current': 'low_risk'}   \n",
    "df = df.replace(x)\n",
    "\n",
    "x = dict.fromkeys(['Late (31-120 days)', 'Late (16-30 days)', 'Default', 'In Grace Period'], 'high_risk')    \n",
    "df = df.replace(x)\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0654be6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features\n",
    "X = df.copy().drop(\"loan_status\", axis=1)\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Create our target\n",
    "y = df.loc[:, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f5b49e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7a6337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c85892e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: Counter({'low_risk': 51352, 'high_risk': 260})\n",
      "Testing Set: Counter({'low_risk': 17118, 'high_risk': 87})\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set:\", Counter(y_train['loan_status']))\n",
    "print(\"Testing Set:\", Counter(y_test['loan_status']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f670d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high_risk       0.73      0.34      0.47        87\n",
      "    low_risk       1.00      1.00      1.00     17118\n",
      "\n",
      "    accuracy                           1.00     17205\n",
      "   macro avg       0.86      0.67      0.73     17205\n",
      "weighted avg       1.00      1.00      1.00     17205\n",
      "\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.9960476605637896\n",
      "Accuracy Score: 0.9960476605637896\n",
      "Balanced Accuracy Score: 0.67209249388625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=1).fit(X_train_scaled, y_train)\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23454992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high_risk       0.00      0.00      0.00        87\n",
      "    low_risk       0.99      1.00      1.00     17118\n",
      "\n",
      "    accuracy                           0.99     17205\n",
      "   macro avg       0.50      0.50      0.50     17205\n",
      "weighted avg       0.99      0.99      0.99     17205\n",
      "\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.9949433304272014\n",
      "Accuracy Score: 0.9949433304272014\n",
      "Balanced Accuracy Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "eclf = ExtraTreesClassifier(random_state=1).fit(X_train_scaled, y_train)\n",
    "y_pred2 = eclf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred2))\n",
    "print(f'Training Score: {eclf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {eclf.score(X_test_scaled, y_test)}')\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred2))\n",
    "print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f101adc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high_risk       0.93      0.30      0.45        87\n",
      "    low_risk       1.00      1.00      1.00     17118\n",
      "\n",
      "    accuracy                           1.00     17205\n",
      "   macro avg       0.96      0.65      0.73     17205\n",
      "weighted avg       1.00      1.00      1.00     17205\n",
      "\n",
      "Training Score: 0.996338060916066\n",
      "Testing Score: 0.9963382737576286\n",
      "Accuracy Score: 0.9963382737576286\n",
      "Balanced Accuracy Score: 0.6493668693168313\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abclf = AdaBoostClassifier(random_state=1).fit(X_train_scaled, y_train)\n",
    "y_pred3 = abclf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred3))\n",
    "print(f'Training Score: {abclf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {abclf.score(X_test_scaled, y_test)}')\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred3))\n",
    "print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
